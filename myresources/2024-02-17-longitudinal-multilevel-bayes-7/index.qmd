---
title: Bayesian analysis of longitudinal multilevel data - part 7  
description: In part 7 of this series, I show how to fit a very simple ODE model using Stan and cmdstanr.
author: Andreas Handel
date: 2024-02-17
date-modified: last-modified
aliases: 
  - ../longitudinal-multilevel-bayesian-analysis-7/
categories: 
- R
- Data Analysis
- Bayesian
- Stan
image: "featured.png"
image-alt: "trajectories generated by ODE model"
execute:
  echo: true
engine: knitr
---



```{r, include=FALSE, cache=FALSE}
knitr::read_chunk('cmdstanr-ode-simple-script.R')
```

# Overview

This tutorial continues [the series of posts](/posts/2022-02-22-longitudinal-multilevel-bayes-1/)
showing how to fit longitudinal data using Bayesian multilevel/hierarchical/mixed-effects models. To be able to follow along, you should start with the first post. Otherwise, the following won't make much sense üòÅ.

This tutorial starts the example where the underlying model is given by a set of ordinary differential equations (ODEs). This was originally meant to be a single post, but -- perhaps not surprisingly -- I couldn't get the model I wanted to work. To debug, I had to go slower and had to resort to first fiddling with a simpler model.

I figured these intermediate steps might be useful for folks, so instead of hiding it and just showing you the final model -- which I eventually managed to get working, -- I decided to also write up these intermediate steps. 

So this post introduces the ODE model and a simple statistical model, and then in the [next post](/longitudinal-multilevel-bayes-8/), I finally do the model I wanted to do.

Here is [the Stan code for this example](stancode-ode-simple.stan) and this is [the R script that runs everything](cmdstanr-ode-simple-script.R).



# Introduction

A while ago, I wrote [a series of tutorials](/posts/2022-02-22-longitudinal-multilevel-bayes-1/) that discuss fitting longitudinal data using Bayesian multilevel/hierarchical/mixed-effects models.

For the first few posts in this series, I used the [`rethinking`](/posts/2022-02-22-longitudinal-multilevel-bayes-2/) and [`brms`](/posts/2022-02-22-longitudinal-multilevel-bayes-3/) packages to run `Stan` models in `R`, without having to write `Stan` code. 

In those examples, I had a simple model that captured the longitudinal data (in my example, virus load) trajectory. For a research project, I now want to implement a model that uses a set of ordinary differential equations (ODEs). I figured to understand what I'm trying to do, I should first teach myself and write it up in a tutorial. 

One can use packages like `rethinking` or `brms` with ODE models, but one still has to write some `Stan` code. I decided instead, for my purpose, it is better to write the full model in `Stan` and then fit it through `cmdstanr` in R.

I had to go slow, so I can follow along üòÅ. I first switched to `cmdstanr` and `Stan` code using [one of the original models](/posts/2024-02-15-longitudinal-multilevel-bayes-5/) and then a [more complex model](/posts/2024-02-16-longitudinal-multilevel-bayes-6/) implemented in Stan. I assume you read those posts. In this post, I'll finally move on to an ODE-based model.




# The idea

The most common types of models used to describe data are those that are non-mechanistic, or phenomenological, as [I like to call them](https://www.nature.com/articles/s41577-019-0235-3). What's meant by that is that the model represents a convenient and suitable way to describe the data, but does not try to capture any information about the underlying mechanisms of the system and processes that led to the observed data.

In contrast, mechanistic models are -- very simplified -- representations of the assumed or known underlying processes. As such, they allow incorporation of expert knowledge, and are potentially better at providing a fuller understanding of the system. Though they also require such a better understanding at the start to even allow using such models. 

That's all I'll say about these models, you can learn more in [this review article I wrote with colleagues](https://www.nature.com/articles/s41577-019-0235-3) or on [this website](https://andreashandel.github.io/SMIcourse/). Both of these resources are immunology-focused, but the general concepts are the same for any subject matter area.

A common way of implementing mechanistic models that describe the dynamics of some system is through ordinary differential equations (ODEs). This is the approach I'll be taking here.


# The ODE model

As a reminder, our outcome/data of interest are virus load time-series trajectories of individuals following infection.

To get an ODE model that can capture the shape of our data, I use a simple basic virus dynamics model. I won't explain this model here, if you want to learn more about these kind of models, see for instance [this short write-up](https://andreashandel.github.io/SMIcourse/A_Few_Simple_Models.html#Simple_Viral_Infection_Model) on my [Simulation Modeling for Immunologists website](https://andreashandel.github.io/SMIcourse/) or [this reference](https://www.nature.com/articles/nri700).

Here are the model equations

$$
\begin{aligned}
\textrm{uninfected cells:} \qquad  \dot U & = -\beta_i UV \\ 
\textrm{infected cells:} \qquad  \dot I & = \beta_i UV - \gamma_i I \\
\textrm{virus:} \qquad  \dot V & = \alpha_i I - \eta_i V
\end{aligned}
$$
This model has 4 parameters, each is indexed by $i$ to indicate that it can differ between individuals. For any ODE model, one needs to not only specify the model parameters but also the starting values of each quantity. To keep things simple, below I assume that the number of uninfected cells and infected cells is known and the same for each individual, and that the virus load is estimated but only depends on dose, no individual-level variation. More generally, it would be possible to let the starting values vary and estimate them from the data.

While the model tracks the dynamics of 3 quantities, we only have data for one, namely the virus $V$. The log of the time-series obtained for $V$ by solving these ODEs is what is now assumed to be the average trajectory, namely what we formerly called $\mu$ in the previous models.



# Mathematical shenanigans

As is common, it turns out that directly coding up the model in the form specified above is not a good idea for several reasons.

First, we have the issue with positive parameters again. The model above assumes all parameters are positive. To enforce that, we can again use the trick of exponentiating the parameters. This is what we'll do. You'll see it in the code below.

Second the values for the model variables change a lot. We start with a lot of uninfected cells (millions or more), no infected cells and a little bit of virus. The virus then grows rapidly, and so do the infected cells. The uninfected cell numbers crash. These extreme changes in variables are hard on the ODE solver. I initially tried to implement the model as written above (after enforcing parameters to be positive by exponentiating), and then in the end take the log of the virus load. That didn't work well. So I decided to just run the whole model in log units. 

That means, the model I'm actually running is


$$
\begin{aligned}
\textrm{uninfected cells:} \qquad  \frac{d}{dt} \log(U) & = -\exp(\beta_i) \log(U) \log(V) \\ 
\textrm{infected cells:} \qquad  \frac{d}{dt} \log(I) & = \exp(\beta_i) \log(U) \log(V) - \exp(\gamma_i) \log(I) \\
\textrm{virus:} \qquad  \frac{d}{dt} \log(V) & = \exp(\alpha_i) \log(I) - \exp(\eta_i) \log(V)
\end{aligned}
$$


I want to re-iterate that this is the same model as above, just doing various transformations to make the code run.


# ODE model exploration

To get a quick idea for the model behavior, I wrote a few lines of R code to run it.

First, we load all packages needed for this whole post/project, and set some variables/paths.

```{r, packages, message=FALSE, warning = FALSE}
```

```{r, setup, message=FALSE, warning = FALSE}
```


Next, a few lines of code to explore the ODE model.

```{r, explore-model}
```

I played around with the parameter values to find some that gives me a curve that looks reasonable.



## The new statistical model

I wanted a statistical model that had the overall structure of the model structure from the previous non-ODE model examples, with the only difference that now the virus trajectory is described by an ODE model. I'll get to this in the next blog post. But I wasn't able to get that model to work and therefore had to resort to building a simpler model first, just to figure out what's going on.

For the simpler model, I used the approach from the last model in the previous post, namely a model for which the main parameters are different for each individual and don't depend on dose or each other. The initial value for the virus variable is assumed to depend on dose. 

I'm not sure what the best mathematical notation is to write down this model, here is an option. I'm showing the ODE model in its original form, without the extra $\exp()$ and $\log()$ notation. The understanding is that model will be implemented as shown in the second model above, with parameters on an exponentiated scale and variables on the log scale. This is reflected in the initial condition values.


$$
\begin{aligned}
\textrm{Outcome} \\
Y_{i,t}   \sim \mathrm{Normal}\left(V_{i,t}, \sigma\right) \\
\\
\textrm{ODE model defining V} \\
\dot U  = -\beta_i UV \\ 
\dot I  = \beta_i UV - \gamma_i I \\
\dot V  = \alpha_i I - \eta_i V \\
\\
\textrm{Starting values for ODE model} \\
\textrm{initial uninfected cells} \qquad U(0) = \log(1E8)  \\
\textrm{initial infected cells} \qquad  I(0) = 0  \\
\textrm{initial virus, to be fit}  \qquad V(0) = V_i[dose] \\
\\
\textrm{Deterministic models for main parameters} \\
\alpha_{i}   =  a_{0,i}  \\
\beta_{i}   =   b_{0,i} \\
\gamma_{i}   =   g_{0,i} \\
\eta_{i}   =   e_{0,i} \\
\end{aligned}
$$
The index $i$ represents indexation with respect to individuals. The index $dose$ indicates the 3 different dose levels. 

As mentioned before, I don't really need both $\alpha, \beta,...$ here and $a_0, b_0,...$, but I'm setting this up this way so it's similar to all previous setups and easy to extend.

To fully specify the model, we need to give all parameters distributions. As before, I'm not showing the exact prior values to prevent it being different than the code, instead I'm only indicating them here with an `X`. See the code for the exact values. 

As mentioned, I'm not yet implementing partial pooling, instead each parameter has some fixed prior distribution. As a reminder, the parameters inside the ODE are the exponentiated version of this, while the starting value for the virus load is on a log scale (so the true value is the exponentiated form, but we never use that, we fully operate on a log scale for all 3 ODE model variables).


$$
\begin{aligned}
\textrm{population-level priors} \\
\sigma  \sim \mathrm{HalfCauchy}(X,X)  \\
a_{0,i} \sim \mathrm{Normal}(X, X) \\
b_{0,i} \sim \mathrm{Normal}(X, X) \\
g_{0,i} \sim \mathrm{Normal}(X, X) \\
e_{0,i} \sim \mathrm{Normal}(X, X) \\
V_i[dose] \sim \mathrm{Normal}(X, X) \\
\end{aligned}
$$


And that's the full model for the simplified case. Now we need to implement it with Stan. 



# Model implementation

We previously used the `brms` and `rethinking` R packages to run our `Stan` models in `R`, without having to write `Stan` code. One can use these packages for ODEs, but still has to write some `Stan` code. I decided instead, for flexibility, I'm writing the full model in `Stan` and then fit it through `cmdstanr` in R.

We'll use the same data as before. We need to reshape it a bit to get it into the format that `cmdstanr` requires. To make things inside the Stan code easier, we added some additional information. Note that the model we implement here won't use all of the data. We keep it in here for the next model.


```{r, data}
```


# Stan code

Next, we need to write the Stan model code. For some of the parts, I took inspiration from [this blog post by Danielle Narravo](https://blog.djnavarro.net/posts/2023-06-10_pop-pk-models/). The code is again in a separate file, linked at the top of this post. 

The code keeps growing. I'm not going to explain it in detail, but will point out a few new parts. 

* There is now a `functions` block which defines the ODE model function. The notation is rather similar to the `deSolve` R implementation shown above. This function is called inside the `generated parameters` block and integrated using the `ode_rk45` routine that is part of Stan. 

* For the `data` part, I'm passing in values for priors for all parameters. I also now have a variable `dose_level` that is an indicator variable taking on values 1,2,3 for the 3 different dose levels, and used to index the starting value for the virus load, which we assume only differs by dose and not individual person.

* There's also a `transformed data` block that computes some indices to keep track of the first and last value of each individual in the long vector of all observations. 

* The ode integration happens inside the `generated parameters` block. We loop over every individual and run the ODE model, then save the results for each individual in the long `virus_pred` vector.


```{.stan include="stancode-ode-simple.stan"}
```


Next, we load and compile the Stan model.

```{r, make_stanmodel, message=FALSE, warning = FALSE, eval=FALSE}
```


# Model fitting settings

As before, we need to specify settings for the MCMC algorithm and starting values (the latter of which is optional but I consider good practice).

```{r, fitconditions}
```

```{r, initialconditions}
```


# Model fitting 


This runs the model. It's not actually run here to speed up generation of this Quarto file, but the code chunk is in the R script, so you can run it.

```{r, run_m1, message=FALSE, warning = FALSE, output = FALSE, eval=FALSE}
```

If you were to run it, you'll find that it takes rather long. That's a major problem with ODE model fitting in a Bayesian framework. Those models take long to run and one needs to run them for each iteration. In the future, I hope to re-implement this in `Julia`, which is a programming language that has faster ODE solvers. But I don't have a ton of Julia experience, so this will come after I fully get this example to work üòÅ.


# Model result loading

To save time, we don't run the model each time, instead we save the results and load them.

```{r, loadfits, message=FALSE, warning = FALSE}
```


# Model exploration

Get the samples.

```{r, get_samples_m1,  warning = FALSE}
```


Model diagnostics.

```{r, diagnose_m1,  warning = FALSE, message = FALSE}
```

Ok, so the sampler isn't quite happy. 

Next, we'll take a look at a summary table for the distributions of some of the model parameters. I cut it off since there are too many to show (each individual as multiple parameters with associated distributions).


```{r, summarize_m1}
```

We can't really compare with the values we used to generate the model since we are using a different model to fit the data. However, since we have a mechanistic model, and the parameters have biological meaning, we can do a reality-check, at least for some of them. For instance the inverse of the parameter $\gamma$ is the lifespan of an infected cell. If we have some knowledge of the system, we can see if our estimate agrees with that. Even without much knowledge, we would still expect an infected cell at minimum to live on average say a few hours -- otherwise it could never produce any virus -- and at most maybe days/weeks/months, depending on the pathogen we model. So if our predictions correspond to lifespans of seconds or millenia, we know something isn't right. The fact that model parameters have biological meaning is unique to mechanistic models. For phenomenological models (e.g., some type of GLM), interpretation of parameters is not as clear. Though even in those situations, one can often spot parameters that make no sense. For instance a prediction that each 1 pound increase in weight for children leads to increase in 1 meter of height is clearly nonsensical. So it's always important to look at the parameter values and contemplate if they make sense, given what we know about the real world.


Let's again look at a few plots to make sure everything looks reasonable. Here I'm showing again a trace plot and a posterior density plot. 

```{r, plot_par_m1,  warning = FALSE}
```

The pairs plot shows a strong correlation between $\beta$ and $\gamma$.


Next, we'll compare prior and posterior distributions. This can give an indication if the priors were selected well or are too broad or overly influential. To be able to show priors, we needed all that extra information in the _generated quantities_ block in the Stan code.


```{r, prep_data_m1}
```


```{r, prior_post_m1}
```

The plots show that the priors don't overly influence the results, the data dominates the posteriors (they move and get more peaked, an indication that the data controls the posterior shape).


I'm skipping the additional diagnostics with the `loo` package, the same code as in the previous examples would work. I'm also not showing the observed versus predicted plot, since we will look at the actual data and model predictions, which for this type of model is more informative.


# Model predictions

Finally, we again want to look at the actual data and the model predictions. It's exactly the same code as for the 2-parameter model.

```{r, make_predictions,  warning = FALSE, message = FALSE}
```

```{r, plot_predictions,  warning = FALSE, message = FALSE}
```

The model fits don't look that great. I'm not sure why the model isn't capturing the data better, if it needs more iterations and/or better choice of priors, or if there's something inherent about the structure of this model not being able to capture the data generated by the 2-parameter model, even though it is more flexible with its 4 parameters.



# Summary and continuation

This completes the first half of the ODE model example. I'm finally ready to implement the more detailed model I really want to look at, which [is covered in the next post](/posts/2024-02-18-longitudinal-multilevel-bayes-8/).







