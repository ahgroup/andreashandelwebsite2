{
  "hash": "566d5e1d6c4ae02d71033b740c8a9c62",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Bayesian analysis of longitudinal multilevel data - part 6  \ndescription: Part 6 of a tutorial showing how to fit directly with Stan and cmdstanr.\nauthor: Andreas Handel\ndate: 2024-02-16\ndate-modified: last-modified\naliases: \n  - ../longitudinal-multilevel-bayesian-analysis-6/\ncategories: \n  - R\n  - Data Analysis\n  - Bayesian\n  - Stan\nimage: \"featured.png\"\nimage-alt: \"Traceplot for several model parameters.\"\nexecute:\n  echo: true\nengine: knitr\n---\n\n\n\n\n# Overview\n\nThis is an extension of [a `cmdstanr`/Stan model](/posts/2024-02-15-longitudinal-multilevel-bayes-5/) to fit longitudinal data using Bayesian multilevel/hierarchical/mixed-effects models. It is a continuation of a prior series of posts. You should [start at the beginning](/posts/2022-02-22-longitudinal-multilevel-bayes-1/). \n\nHere is [the Stan code for this example](stancode-4par.stan) and this is [the R script that runs everything](cmdstanr-4par-script.R).\n\n\n# Introduction\n\nAs described [in the prior post](/posts/2024-02-15-longitudinal-multilevel-bayes-5/) I want to implement an ordinary differential equation (ODE) model with Stan. I am slowly building up to that. \n\nWhile I had planned to hop from the 2-parameter `cmdstanr` and Stan model straight to the ODE model, I ended up deciding on one more intermediate step. Namely, I know that the ODE model I want to use has 4 main parameters, as opposed to the 2 parameters used here. I figured I might first build a more complex, 4-parameter non-ODE model before I try to implement the ODE model.\n\n\n# New deterministic model \n\nThe obvious candidate for that 4-parameter model is the equation I [mentioned previously](/posts/2022-02-25-longitudinal-multilevel-bayes-4/#alternative-model-for-time-series-trajectory) and that we ended up using in [one of our  papers](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10310361/). This equation was introduced as a good model to fit virus load data for an acute infection in [this paper](https://bmcpublichealth.biomedcentral.com/articles/10.1186/1471-2458-11-S1-S10).\n\nI'm deviating from the original paper by giving the parameters different names ($\\alpha$, $\\beta$, $\\gamma$, $\\eta$ instead of $p$, $g$, $d$, $k$) to be consistent with what I've been doing so far. \n\nAlso, since the original model was developed and set up with the assumptions that all 4 main parameters are positive, I need to ensure that by using the [previously described approach](/posts/2022-02-22-longitudinal-multilevel-bayes-1/#numerical-trickeries) of exponentiating the parameters. \n\nThis leads to this equation for the virus load trajectory.\n\n$$\n\\begin{aligned}\n\\mu_{i,t} = \\log\\left( \\frac{2 \\exp(\\alpha_{i})}{e^{-\\exp(\\beta_{i})  (t_i - \\exp(\\gamma_{i}))} + e^{\\exp(\\eta_{i})  (t_i - \\exp(\\gamma_{i}))}}\\right).\\\\\n\\end{aligned}\n$$\n\nHere's a bit of R code to explore this equation and to determine values for parameter priors and starting conditions that lead to curves that are consistent with our simulated data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# brief plotting of model to get idea for priors\nt = seq(0.1,40,length=100) \n# all parameters are the log of their original values\nalph = 30; # approximately the peak of virus\nbet = 1.5; # approx. growth rate\ngamm = 2; # approx. peak time\net = 0.3; # approx. decay rate\nnum  = 2*exp(alph)\nd1 = exp( - exp(bet)*(t - exp(gamm)) )\nd2 =  exp( exp(et) * (t - exp(gamm)) )\nmu = log( num /(d1 + d2) ) \nplot(t,mu, type = \"l\") #looks somewhat like virus load in acute \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/explore-model-1.png){width=672}\n:::\n:::\n\n\n\n\n## Full model structure\n\nThe rest of the model follow the previous one, just with more parameters. They all get their own equations. Here are the main components of the the new  model.\n\n\n$$\n\\begin{aligned}\n\\textrm{Outcome} \\\\\nY_{i,t}   \\sim \\mathrm{Normal}\\left(\\mu_{i,t}, \\sigma\\right) \\\\\n\\\\\n\\textrm{main model describing the virus trajectory} \\\\\n\\mu_{i,t} = \\log\\left( \\frac{2 \\exp(\\alpha_{i})}{e^{-\\exp(\\beta_{i})  (t_i - \\exp(\\gamma_{i}))} + e^{\\exp(\\eta_{i})  (t_i - \\exp(\\gamma_{i}))}}\\right).\\\\\n\\\\\n\\textrm{Deterministic models for main parameters} \\\\\n\\alpha_{i}   =  a_{0,i} + a_1 \\left(\\log (D_i) - \\log (D_m)\\right)  \\\\\n\\beta_{i}   =  b_{0,i} + b_1 \\left(\\log (D_i) - \\log (D_m)\\right) \\\\\n\\gamma_{i}   =  g_{0,i} + g_1 \\left(\\log (D_i) - \\log (D_m)\\right) \\\\\n\\eta_{i}   =  e_{0,i} + e_1 \\left(\\log (D_i) - \\log (D_m)\\right) \\\\\n\\end{aligned}\n$$\n\n\n## Parameter distributions\n\nTo fully specify the model, we need to give all parameters distributions. \nHere are the distributions for the population-level parameters. These do not vary between individuals. I'm choosing values for the prior distributions assuming that dose will lead to an increase in peak, time to peak and growth rate, and a reduction in decay rate. I'm only indicating the values with an `X` below since I keep changing them in the code and then they are out of sync here. Check the R script to see the chosen values.\n\n\n$$\n\\begin{aligned}\n\\textrm{population-level priors} \\\\\n\\sigma  \\sim \\mathrm{Exponential}(1)  \\\\\na_1 \\sim \\mathrm{Normal}(X,X) \\\\\nb_1 \\sim \\mathrm{Normal}(X,X) \\\\\ng_1 \\sim \\mathrm{Normal}(X,X) \\\\\ne_1 \\sim \\mathrm{Normal}(X,X) \\\\\n\\end{aligned}\n$$\n\n\nIn addition, we allow some parameters to differ between individuals, and we'll implement hyper-parameters to allow these values to inform each other across individuals. This is again the adaptive pooling concept discussed previously.\n\nI'm setting values for the prior distributions similar to values we used in our [previous study](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10310361/). That's probably not ideal since the data is different, but hopefully close enough that the code will run.\n\n\n$$\n\\begin{aligned}\n\\textrm{individal-level priors} \\\\\na_{0,i} \\sim \\mathrm{Normal}(\\mu_a, \\sigma_a) \\\\\nb_{0,i}  \\sim \\mathrm{Normal}(\\mu_b, \\sigma_b) \\\\\ng_{0,i} \\sim \\mathrm{Normal}(\\mu_g, \\sigma_g) \\\\\ne_{0,i}  \\sim \\mathrm{Normal}(\\mu_e, \\sigma_e) \\\\\n\\\\\n\\textrm{hyper priors} \\\\\n\\mu_a  \\sim \\mathrm{Normal}(25, 5) \\\\\n\\mu_b  \\sim \\mathrm{Normal}(3, 1) \\\\\n\\mu_g  \\sim \\mathrm{Normal}(0, 1) \\\\\n\\mu_e  \\sim \\mathrm{Normal}(-1, 0.5) \\\\\n\\sigma_a  \\sim \\mathrm{Exponential}(1)  \\\\\n\\sigma_b  \\sim \\mathrm{Exponential}(1)  \\\\\n\\sigma_g  \\sim \\mathrm{Exponential}(1)  \\\\\n\\sigma_e  \\sim \\mathrm{Exponential}(1)  \\\\\n\\end{aligned}\n$$\n\n\n\nAnd that's the full model. The basic structure is the same as before, but the model is bigger because I'm now modeling the virus trajectory (given by $\\mu_{i,t}$) with 4 main parameters.\n\n\n# Model implementation\n\nWe'll follow exactly the same setup as [in the previous post](/posts/2024-02-15-longitudinal-multilevel-bayes-5/).\nLinks to the Stan and R code files are given at the top of this document.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary('here') #for file loading\nlibrary('dplyr') # for data manipulation\nlibrary('ggplot2') # for plotting\nlibrary('fs') #for file path\nlibrary('cmdstanr') #for model fitting\nlibrary('bayesplot') #for plotting results\nlibrary('posterior') #for post-processing\nlibrary('loo') #for model diagnostics\n```\n:::\n\n\n\nWe'll use the same data as before. I'm making one more change. Instead of hard-coding the values for the prior distributions into the Stan code, I'm assigning some of them labels and then pass values into Stan from R. This makes exploring the Stan model more flexible, I don't need to re-edit the Stan code if I want to try different values for the priors. These values for the priors need to be passed in as part of the data. I could do this for all parameters, but out of laziness, and because I don't change them much, I'm hard-coding the sigma parameters.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# adjust as necessary\nsimdatloc <- here::here('posts','2022-02-22-longitudinal-multilevel-bayes-1','simdat.Rds')\nsimdat <- readRDS(simdatloc)\nNind = length(unique(simdat$m3$id))\nNtot =  length(simdat$m3$id)\n# values for prior distributions\n# allows for exploring different values without having to edit Stan model code\npriorvals = list(mu_a_mu = 30, mu_a_sd = 5,\n                 mu_b_mu = 1.5, mu_b_sd = 1,\n                 mu_g_mu = 2, mu_g_sd = 1,\n                 mu_e_mu = 0.5, mu_e_sd = 1,\n                 a1_mu = 0.5, a1_sd = 1,\n                 b1_mu = 0.1, b1_sd = 1,\n                 g1_mu = 0.1, g1_sd = 1,\n                 e1_mu = -0.1, e1_sd = 1\n)\n\n# all data as one list, this is how Stan needs it\nfitdat=list(id=simdat[[3]]$id,\n            outcome = simdat[[3]]$outcome,\n            time = simdat[[3]]$time,\n            dose_adj = simdat[[3]]$dose_adj[1:Nind], #first Nind values\n            Ntot =  Ntot,\n            Nind = Nind\n            )\nfitdat = c(fitdat,priorvals)\n```\n:::\n\n\n\n# Stan code\n\nNext, we need to write the Stan model code. While one could embed Stan code inside an R script, I find it best to write that code in a separate file and then load it. Here, the code is in file called `stancode-4par.stan`. This code loads and compiles the Stan model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make Stan model. \nstanfile <- here('posts','2024-02-16-longitudinal-multilevel-bayes-6',\"stancode-4par.stan\")\nstanmod1 <- cmdstanr::cmdstan_model(stanfile, \n                                    pedantic=TRUE, \n                                    force_recompile=TRUE)\n```\n:::\n\n\nNext, we'll take a quick look at the Stan model code. The model is basically like the previous one, updated to reflect the model equations above. As mentioned above, instead of hard-coding values for prior distributions inside the Stan code, I'm passing some of them into the code as data. The advantage of passing them in is that I can more quickly play around with different values and see how results change. It also ensures that I use the same values in all parts of the model (e.g., `model` and `generated quantities` blocks).\n\n```{.stan include=\"stancode-4par.stan\"}\n```\n\n\n\n\n## Model fitting settings\n\nThese are the settings for the model fitting routine. Basically the same as before, only more initial conditions now because we have more parameters. And of course different values, since our model changed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#settings for fitting\nfs_m1 = list(warmup = 1500,\n             sampling = 1000, \n             max_td = 20, #tree depth\n             adapt_delta = 0.99999,\n             chains = 5,\n             cores  = 5,\n             seed = 1234,\n             save_warmup = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# separate definition of initial values, added to fs_m1 structure \n# a different sample will be drawn for each chain\n# there's probably a better way to do that than a for loop\nset.seed(1234) #make inits reproducible\ninit_vals_1chain <- function() (list(mu_a = runif(1,25,35), \n                                     mu_b = runif(1,1,2),\n                                     mu_g = runif(1,1.5,2.5),\n                                     mu_e = runif(1,0,1),\n                                     sigma_a = runif(1,0,1),\n                                     sigma_b = runif(1,0,1),\n                                     sigma_g = runif(1,0,1),\n                                     sigma_e = runif(1,0,1),\n                                     a0 = runif(Nind,25,35),\n                                     b0 = runif(Nind,1,2),\n                                     g0 = runif(Nind,1.5,2.5),\n                                     e0 = runif(Nind,0,1),\n                                     a1 = runif(1,0.5,0.6),\n                                     b1 = runif(1,0.1,0.1),\n                                     g1 = runif(1,0.1,0.1),\n                                     e1 = runif(1,-0.1,-0.1),\n                                     sigma = runif(1,0,1)))\ninits = NULL\nfor (n in 1:fs_m1$chains)\n{\n  inits[[n]] = init_vals_1chain()\n}\nfs_m1$init = inits\n```\n:::\n\n\n\n# Model fitting \n\nThis runs the model. It's not actually run here to speed up generation of this Quarto file, but the code chunk is in the R script, so you can run it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_m1 <- stanmod1$sample(data = fitdat,\n                          chains = fs_m1$chains,\n                          init = fs_m1$init,\n                          seed = fs_m1$seed,\n                          parallel_chains = fs_m1$chains,\n                          iter_warmup = fs_m1$warmup,\n                          iter_sampling = fs_m1$sampling,\n                          save_warmup = fs_m1$save_warmup,\n                          max_treedepth = fs_m1$max_td,\n                          adapt_delta = fs_m1$adapt_delta\n)\n```\n:::\n\n\n\n# Model result loading\n\nTo save time, we don't run the model each time, instead we save the results and load them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading previously saved fit.\n# useful if we don't want to re-fit\n# every time we want to explore the results.\n# since the file is too large for GitHub\n# it is stored in a local cloud-synced folder\n# adjust accordingly for your setup\nfilepath = fs::path(\"D:\",\"Dropbox\",\"datafiles\",\"longitudinalbayes\",\"cmdstanr4par\", ext=\"Rds\")\nif (!fs::file_exists(filepath))\n{\n  filepath = fs::path(\"C:\",\"Data\",\"Dropbox\",\"datafiles\",\"longitudinalbayes\",\"cmdstanr4par\", ext=\"Rds\")\n}\nres_m1 <- readRDS(filepath)\n```\n:::\n\n\n# Model diagnostics\n\nFirst, we look at diagnostics from the fitting routine to make sure nothing obviously wrong shows up.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_m1$cmdstan_diagnose()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFile C:/Users/Andreas/AppData/Local/Temp/RtmpS6yIUL/stancode-4par-202402210947-1-95dd46.csv not found\nFile C:/Users/Andreas/AppData/Local/Temp/RtmpS6yIUL/stancode-4par-202402210947-2-95dd46.csv not found\nFile C:/Users/Andreas/AppData/Local/Temp/RtmpS6yIUL/stancode-4par-202402210947-3-95dd46.csv not found\nFile C:/Users/Andreas/AppData/Local/Temp/RtmpS6yIUL/stancode-4par-202402210947-4-95dd46.csv not found\nFile C:/Users/Andreas/AppData/Local/Temp/RtmpS6yIUL/stancode-4par-202402210947-5-95dd46.csv not found\nNo valid input files, exiting.\n```\n\n\n:::\n:::\n\n\nOk, so the sampler isn't quite happy. We should sample more and more stringently, but that would take very long. So for the purpose of this investigation, and given that I'm only exploring this model as a stepping stone to the ODE model I'm really interested in, I'll leave it the way it is. If this were an actual research project, I would obviously need to improve the model performance.\n\nAnother important check are to make a few diagnostic plots. We'll first need to get the samples, both with and without warmups, to be able to make various figures.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#this uses the posterior package to get draws\nsamp_m1 <- res_m1$draws(inc_warmup = FALSE, format = \"draws_df\")\nallsamp_m1 <- res_m1$draws(inc_warmup = TRUE, format = \"draws_df\")\n```\n:::\n\n\nNow we can look at a few figures. Here I'm again showing a trace plot and a pairs plot. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# only main parameters, excluding parameters that we have for each individual, is too much\nplotpars = c(\"a1\",\"b1\",\"g1\",\"e1\",\"sigma\")\nbayesplot::color_scheme_set(\"viridis\")\nbp1 <- bayesplot::mcmc_trace(samp_m1, pars = plotpars)\nbp2 <- bayesplot::mcmc_pairs(samp_m1, pars = plotpars)\nplot(bp1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_par_m1-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(bp2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_par_m1-2.png){width=672}\n:::\n:::\n\n\nThe plots look reasonable. Well-mixing chains and no noticeable correlations among parameters.\n\n\n# Model results\n\nNow that we think we can somewhat trust that the sampling worked, we'll take a look at a summary table for the distributions of some of the model parameters. I cut it off since there are too many to show (each individual as multiple parameters with associated distributions). We'll also look at the posteriors in a graph.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(head(res_m1$summary(),15))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 × 10\n   variable       mean   median      sd     mad       q5      q95  rhat ess_bulk\n   <chr>         <dbl>    <dbl>   <dbl>   <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n 1 lp__     -388.      -3.89e+2 4.52e+1 4.92e+1 -4.60e+2 -3.11e+2  1.05     67.5\n 2 sigma       5.87     5.86e+0 2.73e-1 2.74e-1  5.44e+0  6.32e+0  1.00   4044. \n 3 sigma_a     0.466    3.37e-1 4.29e-1 3.61e-1  3.59e-2  1.32e+0  1.07     52.7\n 4 sigma_b     0.0152   1.16e-2 1.30e-2 1.16e-2  1.57e-3  4.03e-2  1.02     78.5\n 5 sigma_g     0.0124   1.03e-2 9.19e-3 8.53e-3  1.74e-3  3.03e-2  1.05     93.7\n 6 sigma_e     0.286    2.79e-1 5.74e-2 5.40e-2  2.06e-1  3.89e-1  1.00   1674. \n 7 a1          3.08     3.08e+0 3.28e-1 3.26e-1  2.55e+0  3.63e+0  1.00   2009. \n 8 b1          0.102    1.02e-1 2.19e-2 2.12e-2  6.65e-2  1.40e-1  1.00    925. \n 9 g1         -0.00560 -5.44e-3 1.57e-2 1.51e-2 -3.22e-2  1.98e-2  1.00    869. \n10 e1         -0.313   -3.12e-1 3.83e-2 3.54e-2 -3.77e-1 -2.54e-1  1.00    753. \n11 mu_a       26.2      2.62e+1 6.54e-1 6.59e-1  2.51e+1  2.72e+1  1.02    443. \n12 mu_b        3.86     3.86e+0 4.34e-2 4.26e-2  3.79e+0  3.93e+0  1.01    245. \n13 mu_g        0.481    4.81e-1 3.09e-2 3.01e-2  4.32e-1  5.34e-1  1.01    242. \n14 mu_e        0.237    2.37e-1 6.90e-2 6.57e-2  1.22e-1  3.48e-1  1.00   1272. \n15 a0[1]      26.3      2.63e+1 8.89e-1 7.93e-1  2.50e+1  2.78e+1  1.01    506. \n# ℹ 1 more variable: ess_tail <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\nbp3 <- bayesplot::mcmc_dens_overlay(samp_m1, pars = plotpars)\nplot(bp3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/results_m1-1.png){width=672}\n:::\n:::\n\n\n\nWe can't really compare with the values we used to generate the model since we are using a different model to fit the data, so we shouldn't expect any parameters to be similar. Thus, I'm not focusing further on the values. Again, for a real research project, you would want to carefully evaluate the parameters (after addressing the problems with the algorithm not working well).\n\n\n\n# Priors and Posteriors\n\nNext, we'll compare prior and posterior distributions. This can give an indication if the priors were selected well or are too broad or overly influential. To be able to show priors, we needed all that extra information in the _generated quantities_ block in the Stan code.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# data manipulation to get in shape for plotting\npostdf1 <- samp_m1 %>% \n  select(!ends_with('prior')) %>% \n  select(!starts_with(\".\")) %>% \n  select(-\"lp__\") %>% \n  select(!contains(\"[\")) \n# awkward way of getting some further parameters\n# namely values from first individual for a0,b0,g0,e0\npostdf2 <- samp_m1 %>%\n           select(contains(\"0[1]\")) %>%\n           rename_with(~ gsub(\"[1]\", \"\", .x, fixed = TRUE) )\npostdf <- cbind(postdf1, postdf2) \npriordf <-  samp_m1 %>% \n  select(ends_with('prior')) %>% \n  rename_with(~ gsub(\"_prior\", \"\", .x, fixed = TRUE) ) \npostlong <- tidyr::pivot_longer(data = postdf, cols = everything() , names_to = \"parname\", values_to = \"value\") %>% mutate(type = \"posterior\")\npriorlong <- tidyr::pivot_longer(data = priordf, cols = everything() , names_to = \"parname\", values_to = \"value\") %>% mutate(type = \"prior\")\nppdf <- dplyr::bind_rows(postlong,priorlong)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_p1 <- ppdf %>%\n  ggplot() +\n  geom_density(aes(x = value, color = type), linewidth = 1) +\n  facet_wrap(\"parname\", scales = \"free\") +\n  theme_minimal()\nplot(m1_p1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/prior_post_m1-1.png){width=672}\n:::\n:::\n\n\nThe plots show that the priors don't overly influence the results, the data dominates the posteriors (they move and get more peaked, an indication that the data controls the posterior shape).\n\n\n# Observed versus predicted\n\n\nAnother useful plot is to look at observed versus predicted results. This is shown in the following plot.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nypred_df <- samp_m1 %>% select(starts_with(\"ypred\"))\nm1_p2 <- bayesplot::ppc_dens_overlay(fitdat$outcome, as.matrix(ypred_df))\nplot(m1_p2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/obs_pred_m1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# just to get a picture that can be shown together with the post\n#ggsave(\"featured.png\",m1_p2)\n```\n:::\n\n\n\nThe data (black line, $y$ variable) and the model (thin green line, $y_{rep}$) are following are a bit off. That indicates that the model didn't fully capture the patterns found in the data and might need modification.\n\n\n# Cross-validation tests\n\nHere's again some further exploration via cross-validation with the `loo` package. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# uses loo package \nloo_m1 <- res_m1$loo(cores = fs_m1$chains, save_psis = TRUE)\nprint(loo_m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nComputed from 5000 by 264 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -861.3 11.1\np_loo        28.3  3.3\nlooic      1722.6 22.1\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     251   95.1%   448       \n (0.5, 0.7]   (ok)        10    3.8%   303       \n   (0.7, 1]   (bad)        3    1.1%   199       \n   (1, Inf)   (very bad)   0    0.0%   <NA>      \nSee help('pareto-k-diagnostic') for details.\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(loo_m1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/loo_m1_part1-1.png){width=672}\n:::\n:::\n\n\nSome values aren't too great. This again suggests that we need to tweak the model or run it longer with more stringent settings.\n\nHere's some more LOO diagnostics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nypred_df <- samp_m1 %>% select(starts_with(\"ypred\"))\nm1_p3 <- bayesplot::ppc_loo_pit_overlay(\n  y = fitdat$outcome,\n  yrep = as.matrix(ypred_df),\n  lw = weights(loo_m1$psis_object)\n)\nplot(m1_p3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/loo_m1_part2-1.png){width=672}\n:::\n:::\n\n\nThe marginal posterior predictive plot suggests some improvement might be possible (so that the solid line is more on top of the green lines). [See here for more](https://mc-stan.org/loo/articles/loo2-example.html).\n\n\n\n# Model predictions\n\nFinally, we again want to look at the actual data and the model predictions. It's exactly the same code as for the 2-parameter model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# averages and CI for \n# estimates of deterministic model trajectory\n# for each observation\n# this is computed in the transformed parameters block of the Stan code\nmu <- samp_m1 |>\n  select(starts_with(\"virus_pred\")) |>\n  apply(2, quantile, c(0.05, 0.5, 0.95)) |>\n  t() \nrownames(mu) <- NULL\n\n# estimate and CI for prediction intervals\n# the predictions factor in additional uncertainty around the mean (mu)\n# as indicated by sigma\n# this is computed in the predicted-quantities block of the Stan code\n# the average of mu and preds should be more or less the same\n# but preds will have wider uncertainty due to the residual variation sigma\npreds <- samp_m1 |>\n  select(starts_with(\"ypred\")) |>\n  apply(2, quantile, c(0.05, 0.5, 0.95)) |>\n  t() \nrownames(preds) <- NULL\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# change dose so it looks nicer in plot\ndose = as.factor(fitdat$dose_adj)\nlevels(dose)[1] <- \"low\"\nlevels(dose)[2] <- \"medium\"\nlevels(dose)[3] <- \"high\"\n\n#place everything into a data frame\nfitpred = data.frame(id = as.factor(fitdat$id),\n                     dose = dose,\n                     time = fitdat$time,\n                     Outcome = fitdat$outcome,\n                     Estimate = mu[,2],\n                     Qmulo = mu[,1], Qmuhi = mu[,3],\n                     Qsimlo = preds[,1], Qsimhi = preds[,3]\n)\n\n#make the plot\npredplot <- ggplot(data = fitpred, aes(x = time, y = Estimate, group = id, color = dose ) ) +\n  geom_line() +\n  geom_ribbon(aes(x=time, ymin=Qmulo, ymax=Qmuhi, fill = dose, color = NULL), alpha=0.3, show.legend = F) +\n  #geom_ribbon(aes(x=time, ymin=Qsimlo, ymax=Qsimhi, fill = dose, color = NULL), alpha=0.1, show.legend = F) +\n  geom_point(aes(x = time, y = Outcome, group = id, color = dose), shape = 1, size = 2, stroke = 2) +\n  scale_y_continuous(limits = c(-30,50)) +\n  labs(y = \"Virus load\",\n       x = \"days post infection\") +\n  theme_minimal() \nplot(predplot)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_predictions-1.png){width=672}\n:::\n:::\n\n\nThe model fits don't look that great. I'm not sure why the model isn't capturing the data better, if it needs more iterations and/or better choice of priors, or if there's something inherent about the structure of this model not being able to capture the data generated by the 2-parameter model, even though it is more flexible with its 4 parameters.\n\n\n\n# Summary and continuation\n\nThis completes the 4-parameter model. I just wanted to get a working model, I'm not really interested in the model results. I just wanted to set the stage for the next version, which is the 4-parameter ODE model. So it's finally time to [tackle that one](/posts/2024-02-17-longitudinal-multilevel-bayes-7/).",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}