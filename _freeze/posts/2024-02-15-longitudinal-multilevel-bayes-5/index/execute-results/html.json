{
  "hash": "91307ab4d99ff0410cc50de2f98695d0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Bayesian analysis of longitudinal multilevel data - part 5  \ndescription: Part 5 of a tutorial showing how to fit directly with Stan and cmdstanr.\nauthor: Andreas Handel\ndate: 2024-02-15\ndate-modified: last-modified\naliases: \n  - ../longitudinal-multilevel-bayesian-analysis-5/\ncategories: \n  - R\n  - Data Analysis\n  - Bayesian\n  - Stan\nimage: \"featured.png\"\nimage-alt: \"Density plot of priors and posteriors for several model parameters.\"\nexecute:\n  echo: true\nengine: knitr\n---\n\n\n\n\n# Overview\n\nThis is a re-implementation of a prior model using `cmdstanr` and Stan code. It is a continuation of a prior series of posts. You should [start at the beginning](/posts/2022-02-22-longitudinal-multilevel-bayes-1/). \n\nHere is [the Stan code for this example](stancode-2par.stan) and this is [the R script that runs everything](cmdstanr-2par-script.R).\n\n\n# Introduction\n\nA while ago, I wrote [a series of tutorials](/posts/2022-02-22-longitudinal-multilevel-bayes-1/) that discuss fitting longitudinal data using Bayesian multilevel/hierarchical/mixed-effects models.\n\nFor a research project, I now want to implement a model that uses a set of ordinary differential equations (ODEs). I figured to understand what I'm trying to do, I should first teach myself and write it up in a tutorial. \n\nTo implement ODEs with Stan, one can't fully use the `rethinking` or `brms` package, one needs to write at least some Stan code. Based on my needs, it is best if I fully implement the model in Stan and call it from R through `cmdstanr`.\n\nI was going to do all at once, but then realized it's better if I first re-implement the old (non ODE-based) setup with Stan code, and then once that's up and running, switch to the ODE model. \n\nSo this post is really an intermediary step to my final goal. It might be of interest to folks to see how to implement this question fully with Stan, even if they don't plan on using ODEs.\n\n\n# Quick recap\n\nI assume you read through the previous posts, at least [part 1](/posts/2022-02-22-longitudinal-multilevel-bayes-1/) which describes the overall setup and the models to be explored, and [part 2](/posts/2022-02-23-longitudinal-multilevel-bayes-2/) which explains the models further and fits the data using `rethinking`. If you didn't, the following won't make much sense üòÅ.\n\nPreviously, I explored several model variants. Here, I'm focusing on the adaptive pooling model (which I previously labeled model 4). As a repeat, here are the model equations.\nI changed the distributions for a few of the parameters since it turned out the ones I used previously made it tricky to sample the priors with Stan and led to convergence issues.\n\n\n$$\n\\begin{aligned}\n\\textrm{Outcome} \\\\\nY_{i,t}   \\sim \\mathrm{Normal}\\left(\\mu_{i,t}, \\sigma\\right) \\\\\n\\\\\n\\textrm{main model describing the virus trajectory} \\\\\n\\mu_{i,t}   =  \\exp(\\alpha_{i}) \\log (t_{i}) -\\exp(\\beta_{i}) t_{i} \\\\\n\\\\\n\\textrm{Deterministic models for main parameters} \\\\\n\\alpha_{i}   =  a_{0,i} + a_1 \\left(\\log (D_i) - \\log (D_m)\\right)  \\\\\n\\beta_{i}   =  b_{0,i} + b_1 \\left(\\log (D_i) - \\log (D_m)\\right) \\\\\n\\\\\n\\textrm{population-level priors} \\\\\n\\sigma  \\sim \\mathrm{Exponential}(1)  \\\\\na_1 \\sim \\mathrm{Normal}(0.1, 0.1) \\\\\nb_1 \\sim \\mathrm{Normal}(-0.1, 0.1) \\\\\n\\\\\n\\textrm{individal-level priors} \\\\\na_{0,i} \\sim \\mathrm{Normal}(\\mu_a, \\sigma_a) \\\\\nb_{0,i}  \\sim \\mathrm{Normal}(\\mu_b, \\sigma_b) \\\\\n\\\\\n\\textrm{hyper priors} \\\\\n\\mu_a  \\sim \\mathrm{Normal}(3, 1) \\\\\n\\mu_b  \\sim \\mathrm{Normal}(0.5, 1) \\\\\n\\sigma_a  \\sim \\mathrm{Exponential}(1)  \\\\\n\\sigma_b  \\sim \\mathrm{Exponential}(1)  \n\\end{aligned}\n$$\n\n\n# Model implementation\n\nI previously used the `brms` and `rethinking` R packages to run our `Stan` models in `R`, without having to write `Stan` code. Of course, we could implement the model above in either of those packages. But in preparation of what I really want to do (using ODE models, and eventually fully account for censored data), I need to switch to coding the model in `Stan`. There might be hacks to do it with `brms` or `rethinking`, but it seems more flexible and also more transparent to just code the full model in `Stan`. We'll still run it through R using `cmdstanr`. Links to the Stan and R code files are given at the top of this document.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary('here') #for file loading\nlibrary('dplyr') # for data manipulation\nlibrary('ggplot2') # for plotting\nlibrary('fs') #for file path\nlibrary('cmdstanr') #for model fitting\nlibrary('bayesplot') #for plotting results\nlibrary('loo') #for model diagnostics\n```\n:::\n\n\nWe'll use the same data as before. We just need to reshape it a bit to get it into the format that `cmdstanr` requires.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# adjust as necessary\nsimdatloc <- here::here('posts','2022-02-22-longitudinal-multilevel-bayes-1','simdat.Rds')\nsimdat <- readRDS(simdatloc)\n# using dataset 3 for fitting\n# also removing anything in the dataframe that's not used for fitting\n# makes the fitting more robust\n# We format the data slightly differently compared to the prior examples\n# We only store the dose for each individual\n# And also add number of observations and individuals\nNind = length(unique(simdat$m3$id))\nNobs =  length(simdat$m3$id)\n\nfitdat=list(id=simdat[[3]]$id,\n            outcome = simdat[[3]]$outcome,\n            time = simdat[[3]]$time,\n            dose_adj = simdat[[3]]$dose_adj[1:Nind], #first Nind values\n            Nobs =  Nobs,\n            Nind = Nind\n            )\n```\n:::\n\n\n\n# Stan code\n\nNext, we need to write the Stan model code. While one could embed Stan code inside an R script, I find it best to write that code in a separate file and then load it. Here, the code is in file called `stancode-2par.stan`. This code loads and compiles the Stan model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make Stan model. \nstanmod1 <- cmdstanr::cmdstan_model(here('posts','2024-02-15-longitudinal-multilevel-bayes-5',\"stancode-2par.stan\"), \n                                    pedantic=TRUE, \n                                    force_recompile=TRUE)\n```\n:::\n\n\nNext, we'll take a quick look at the Stan model code. I added some comments to the Stan model, but if you have never written Stan code, this is likely not fully clear. I won't try to explain Stan code n detail here. There are lots of good resources on the [Stan website](https://mc-stan.org/) and other places online. I'm sure you'll find something that you find accessible to learn the basics of writing Stan code.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(stanmod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n//\n// Stan code for fitting a hierarchical model to time-series data\n//\n\ndata{\n   int<lower = 1> Nobs; //number of observations\n   int<lower = 1> Nind; //number of individuals\n   vector[Nobs] outcome; //virus load\n   vector[Nobs] time; // times at which virus load is measured\n   vector[Nind] dose_adj; //dose after adjustment, 1 value per individual\n   array[Nobs] int id;  //vector of person IDs to keep track which data points belong to whom\n}\n\nparameters{\n     //  population variance\n     real<lower=0> sigma;\n     // population-level dose dependence parameters\n     real a1;\n     real b1;\n     // individual level variation parameters\n     vector[Nind] a0;\n     vector[Nind] b0;\n     // hyper-parameters to implement adaptive pooling\n     real mu_a;\n     real mu_b;\n     real<lower=0> sigma_a;\n     real<lower=0> sigma_b;\n} // close parameters block\n\n\n// Generated/intermediate parameters\ntransformed parameters{\n    // predicted virus load from model\n    vector[Nobs] virus_pred; \n    // main model parameters\n    // each individual has their potentially own value \n    vector[Nind] alpha;\n    vector[Nind] beta;\n \n    // compute main model parameters\n    for ( i in 1:Nind ) {\n        alpha[i] = a0[i] + a1 * dose_adj[i];\n        beta[i] = b0[i] + b1 * dose_adj[i];\n    }\n    // loop over all observations\n    // since paramaters are saved in vectors of length corresponding to number of individuals\n    // we need to index with that extra id[i] notation\n    for (i in 1:Nobs)\n    {\n      virus_pred[i] = exp(alpha[id[i]]) * log(time[i]) - exp(beta[id[i]]) * time[i] ;\n    }\n} // close transformed parameters block\n\n\n\nmodel{\n\n    // hyper-priors to allow for adaptive pooling among individuals \n    mu_a ~ normal( 3 , 1 );\n    mu_b ~ normal( 0.5 , 1 );\n    sigma_a ~ exponential(  1 );\n    sigma_b ~ exponential(  1 );\n  \n    // individual variation of each ODE model parameter\n    a0 ~ normal( mu_a , sigma_a );\n    b0 ~ normal( mu_b , sigma_b );\n  \n    // average dose-dependence of each ODE model parameter\n    a1 ~ normal( 0.1 , 0.1); \n    b1 ~ normal( -0.1 , 0.1);\n  \n    // residual population variation\n    sigma ~ exponential(  1 ); \n    \n    outcome ~ normal( virus_pred, sigma );\n} // close model block\n\n// this code block is not needed for the model fitting\n// but it's useful to compute quantities that one can use later\n// for model diagnostics and exploration\ngenerated quantities {\n    // define quantities that are computed in this block\n    vector[Nobs] ypred;\n    vector[Nobs] log_lik;\n    real<lower=0> sigma_prior;\n    real<lower=0> sigma_a_prior;\n    real<lower=0> sigma_b_prior;\n    real a1_prior;\n    real b1_prior;\n    real mu_a_prior;\n    real mu_b_prior;\n    real a0_prior;     // same prior for each individual so only specify one\n    real b0_prior;     \n    \n    \n    // this is so one can plot priors and compare with posterior later   \n    // simulate the priors\n    sigma_prior = exponential_rng(  1 );\n    sigma_a_prior =  exponential_rng( 1 );\n    sigma_b_prior = exponential_rng(  1 );\n    a1_prior = normal_rng( 0.1 , 0.1);\n    b1_prior = normal_rng( -0.1 , 0.1);\n    mu_a_prior = normal_rng( 3 , 1 );\n    mu_b_prior = normal_rng( 0.5 , 1 );\n    a0_prior = normal_rng(mu_a, sigma_a);\n    b0_prior = normal_rng(mu_b, sigma_b);\n  \n  // compute log-likelihood and predictions\n    for(i in 1:Nobs)\n    {\n      log_lik[i] = normal_lpdf(outcome[i] | virus_pred[i], sigma);\n      ypred[i] = normal_rng(virus_pred[i], sigma);\n    }\n} //end generated quantities block \n```\n\n\n:::\n:::\n\n\n\nNote that the `generated quantities` block is not technically part of the model, and we would get the same results without it. But it is included to compute priors, likelihood and posterior predictions, so we can explore those later. You'll see that used below.\nWhile we could have all the information that's inside the `transformed parameters` block part of the `model` block, that would mean that the `generated quantities` code bits can't access that information. Therefore, all of these intermediate steps are done in `transformed parameters` and then used in both the `model` and the `generated quantities` block. I generally find it easiest to have any distributional/probabilistic bits of code (those that include the `~` sign) in the `model` block, and everything else as much as possible in `transformed parameters`.\n\n\n# Model fitting settings\n\nTo fully specify a model, we need to define the details of the model run (e.g., the random seed, the number of warm-up and sampling steps). This often requires some tuning to find the right values. It is generally a good idea to start with fewer iterations and less stringent fitting criteria while debugging the code. Once everything seems working, one can do one long final run. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#settings for fitting\n#keeping values somewhat low to make things run reasonably fast\n#for 'production' you would probably want to sample more \n#and set more stringent conditions\nfs_m1 = list(warmup = 1500,\n             sampling = 1000, \n             max_td = 15, #tree depth\n             adapt_delta = 0.999,\n             chains = 5,\n             cores  = 5,\n             seed = 1234,\n             save_warmup = TRUE)\n```\n:::\n\n\n\nIt is also a good idea to specify starting values for the parameters. Models can be run without providing starting values (also called initial conditions). In that case, `cmdstanr` will pick default values. However, setting starting values can often improve convergence and thus cut down on required computing time. It also requires one to think a bit more carefully about their model, which is a good thing üòÅ.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# separate definition of initial values, added to fs_m1 structure \n# a different sample will be drawn for each chain\n# there's probably a better way to do that than a for loop\nset.seed(1234) #make inits reproducible\ninit_vals_1chain <- function() (list(mu_a = runif(1,1,3), \n                                     mu_b = runif(1,0,1),\n                                     sigma_a = runif(1,1,10),\n                                     sigma_b = runif(1,1,10),\n                                     a1 = rnorm(1,-0.2,0.2),\n                                     b1 = rnorm(1,-0.2,0.2),\n                                     sigma = runif(1,1,10)))\ninits = NULL\nfor (n in 1:fs_m1$chains)\n{\n  inits[[n]] = init_vals_1chain()\n}\nfs_m1$init = inits\n```\n:::\n\n\n\n# Model fitting \n\nAt this point, we have specified everything necessary to run the model. This runs the model with the specified settings. I'm supressing the output but it's useful to look at it when you run it to make sure the sampler is running ok.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_m1 <- stanmod1$sample(data = fitdat,\n                          chains = fs_m1$chains,\n                          init = fs_m1$init,\n                          seed = fs_m1$seed,\n                          parallel_chains = fs_m1$chains,\n                          iter_warmup = fs_m1$warmup,\n                          iter_sampling = fs_m1$sampling,\n                          save_warmup = fs_m1$save_warmup,\n                          max_treedepth = fs_m1$max_td,\n                          adapt_delta = fs_m1$adapt_delta\n)\n```\n:::\n\n\n\n# Model diagnostics\n\nFirst, we look at diagnostics from the fitting routine to make sure nothing obviously wrong shows up.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(res_m1$cmdstan_diagnose())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nProcessing csv files: C:/Users/Andreas/AppData/Local/Temp/RtmpkZzS9W/stancode-2par-202402131308-1-0863ea.csvWarning: non-fatal error reading adaptation data\n, C:/Users/Andreas/AppData/Local/Temp/RtmpkZzS9W/stancode-2par-202402131308-2-0863ea.csvWarning: non-fatal error reading adaptation data\n, C:/Users/Andreas/AppData/Local/Temp/RtmpkZzS9W/stancode-2par-202402131308-3-0863ea.csvWarning: non-fatal error reading adaptation data\n, C:/Users/Andreas/AppData/Local/Temp/RtmpkZzS9W/stancode-2par-202402131308-4-0863ea.csvWarning: non-fatal error reading adaptation data\n, C:/Users/Andreas/AppData/Local/Temp/RtmpkZzS9W/stancode-2par-202402131308-5-0863ea.csvWarning: non-fatal error reading adaptation data\n\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n$status\n[1] 0\n\n$stdout\n[1] \"Processing csv files: C:/Users/Andreas/AppData/Local/Temp/RtmpkZzS9W/stancode-2par-202402131308-1-0863ea.csvWarning: non-fatal error reading adaptation data\\r\\n, C:/Users/Andreas/AppData/Local/Temp/RtmpkZzS9W/stancode-2par-202402131308-2-0863ea.csvWarning: non-fatal error reading adaptation data\\r\\n, C:/Users/Andreas/AppData/Local/Temp/RtmpkZzS9W/stancode-2par-202402131308-3-0863ea.csvWarning: non-fatal error reading adaptation data\\r\\n, C:/Users/Andreas/AppData/Local/Temp/RtmpkZzS9W/stancode-2par-202402131308-4-0863ea.csvWarning: non-fatal error reading adaptation data\\r\\n, C:/Users/Andreas/AppData/Local/Temp/RtmpkZzS9W/stancode-2par-202402131308-5-0863ea.csvWarning: non-fatal error reading adaptation data\\r\\n\\r\\n\\r\\nChecking sampler transitions treedepth.\\r\\nTreedepth satisfactory for all transitions.\\r\\n\\r\\nChecking sampler transitions for divergences.\\r\\nNo divergent transitions found.\\r\\n\\r\\nChecking E-BFMI - sampler transitions HMC potential energy.\\r\\nE-BFMI satisfactory.\\r\\n\\r\\nEffective sample size satisfactory.\\r\\n\\r\\nSplit R-hat values satisfactory all parameters.\\r\\n\\r\\nProcessing complete, no problems detected.\\r\\n\"\n\n$stderr\n[1] \"\"\n\n$timeout\n[1] FALSE\n```\n\n\n:::\n:::\n\n\nThings look reasonably good, no obvious problems.\n\n\nAnother important check are to make a few diagnostic plots. We'll first need to get the samples, both with and without warmups, to be able to make various figures.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#this uses the posterior package to get draws\nsamp_m1 <- res_m1$draws(inc_warmup = FALSE, format = \"draws_df\")\nallsamp_m1 <- res_m1$draws(inc_warmup = TRUE, format = \"draws_df\")\n```\n:::\n\n\nNow we can look at a few figures. Here I'm showing a trace plot  and a pairs plot. I'm not discussing the plots in detail, you can look up the help file for each R command to learn more.\n\nNote that I'm including some priors here. That's not too meaningful since the prior distributions do not change as the fitting proceeds. Still, it won't hurt to see them. If for some reason the trace plots for the priors look strange (e.g., indicating poor mixing), it means something in the code is wrong.  Similarly, none of the priors should show correlations with each other in the pairs plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# only main parameters, excluding parameters that we have for each individual, is too much\nplotpars = c(\"a1\",\"b1\",\"a1_prior\",\"b1_prior\",\"sigma\")\nbayesplot::color_scheme_set(\"viridis\")\nbp1 <- bayesplot::mcmc_trace(samp_m1, pars = plotpars)\nbp2 <- bayesplot::mcmc_pairs(samp_m1, pars = plotpars)\nplot(bp1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_par_m1-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(bp2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_par_m1-2.png){width=672}\n:::\n:::\n\n\nThe plots look reasonable. Well-mixing chains and no noticeable correlations among parameters.\n\n# Model results\n\nNow that we think we can somewhat trust that the sampling worked, we'll take a look at a summary table for the distributions of some of the model parameters. I cut it off since there are too many to show (each individual as multiple parameters with associated distributions). We'll also look at the posteriors in a graph.\n\n\n\n::: {.cell}\n\n:::\n\n\n\nThe estimates for the parameters are fairly close to those used to simulate the data and obtained [previously](/posts/2022-02-23-longitudinal-multilevel-bayes-2/#models-4-and-4a). That's reassuring, since we just re-fit the same model[^priors] using a different R package, we really want to get the same results. \n\n[^priors]: We'll, it's almost the same model, as I mentioned above some of the prior distributions got changed, but that did fortunately not impact our posterior estimates by much.\n\n\n\n## Priors and Posteriors\n\nNext, we'll compare prior and posterior distributions. This can give an indication if the priors were selected well or are too broad or overly influential. To be able to show priors, we needed all that extra information in the _generated quantities_ block in the Stan code. \nThe individual-level posteriors for $a_0[i]$ and $b_0[i]$ are omitted since there are too many. With a bit more data wrangling, one could plot the averages for these parameters, but I couldn't quickly think of how to do it, so I'm skipping it üòÅ. The priors for these parameters are shown since they same for each individual. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# data manipulation to get in shape for plotting\npostdf <- samp_m1 %>% select(!ends_with('prior')) %>% select(!starts_with(\".\")) %>% select(-\"lp__\") %>% select(!contains(\"[\"))\npriordf <- samp_m1 %>% select(ends_with('prior')) %>% rename_with(~ gsub(\"_prior\", \"\", .x, fixed = TRUE) ) \npostlong <- tidyr::pivot_longer(data = postdf, cols = everything() , names_to = \"parname\", values_to = \"value\") %>% mutate(type = \"posterior\")\npriorlong <- tidyr::pivot_longer(data = priordf, cols = everything() , names_to = \"parname\", values_to = \"value\") %>% mutate(type = \"prior\")\nppdf <- dplyr::bind_rows(postlong,priorlong)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_p1 <- ppdf %>%\n  ggplot() +\n  geom_density(aes(x = value, color = type), linewidth = 1) +\n  facet_wrap(\"parname\", scales = \"free\") +\n  theme_minimal()\nplot(m1_p1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/prior_post_m1-1.png){width=672}\n:::\n:::\n\n\nThe plots show that the priors don't overly influence the results, the data dominates the posteriors (they move and get more peaked, an indication that the data controls the posterior shape).\n\n\n## Observed versus predicted\n\nAnother useful plot is to look at observed versus predicted results. This is shown in the following plot. The data (black line, $y$ variable) and the model (thin green line, $y_{rep}$) are following each other fairly closely. That's a good sign. Systematic deviations would indicate that the model didn't fully capture the patterns found in the data and might need modification.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nypred_df <- samp_m1 %>% select(starts_with(\"ypred\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Dropping 'draws_df' class as required metadata was removed.\n```\n\n\n:::\n\n```{.r .cell-code}\nm1_p2 <- bayesplot::ppc_dens_overlay(fitdat$outcome, as.matrix(ypred_df))\nplot(m1_p2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/obs_pred_m1-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Cross-validation tests\n\nWe can explore further doing cross-validation with the `loo` package. For this to work, the Stan code needs to include computation of the log-likelihood (stored in a variable called `log_lik`). We included that in the `Stan` code for this model.\n\nHere are the diagnostics we get from `loo`. I won't go into the details of cross-validation and LOO here, see the [`loo` package website](https://mc-stan.org/loo/) for good explanations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# uses loo package \nloo_m1 <- res_m1$loo(cores = fs_m1$chains, save_psis = TRUE)\nprint(loo_m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nComputed from 5000 by 264 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -419.6 12.1\np_loo        46.5  4.9\nlooic       839.2 24.2\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     233   88.3%   1186      \n (0.5, 0.7]   (ok)        22    8.3%   312       \n   (0.7, 1]   (bad)        8    3.0%   56        \n   (1, Inf)   (very bad)   1    0.4%   130       \nSee help('pareto-k-diagnostic') for details.\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(loo_m1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/loo_m1_part1-1.png){width=672}\n:::\n:::\n\n\nSome values aren't too great. But it's only a few and it's very likely that if we were to run the model with more iterations and more stringent settings, we'll get even better results. You can give it a try üòÅ. \n\nHere's some more LOO diagnostics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nypred_df <- samp_m1 %>% select(starts_with(\"ypred\"))\nm1_p3 <- bayesplot::ppc_loo_pit_overlay(\n  y = fitdat$outcome,\n  yrep = as.matrix(ypred_df),\n  lw = weights(loo_m1$psis_object)\n)\nplot(m1_p3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/loo_m1_part2-1.png){width=672}\n:::\n:::\n\n\nThe marginal posterior predictive plot suggests some improvement might be possible (so that the solid line is more on top of the green lines). [See here for more](https://mc-stan.org/loo/articles/loo2-example.html).\n\n\n# Model predictions\n\n\n\n\n\n# Summary and continuation\n\nThis completes the `cmdstanr`/`Stan` re-implementation and exploration of one of the previously explored models. Comparing the results to those found previously, we find good agreement. That's comforting.\n\nWhile I had planned to now implement the ODE model as a next step, I ended up deciding on one more intermediate step. Namely, I know that the ODE model I want to use has 4 main parameters, as opposed to the 2 parameters used here. I figured I might first build a more complex, 4-parameter non-ODE model before I switch. The obvious candidate for that 4-parameter model is the equation I [mentioned previously](/posts/2022-02-25-longitudinal-multilevel-bayes-4/#alternative-model-for-time-series-trajectory) and that we ended up using in [our paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10310361/).\n\nSo [the next part in this series](/posts/2024-02-16-longitudinal-multilevel-bayes-6/) is a more complex non-ODE model. I recommend you go there and at least skim through it. Nothing much new is happening, but it sets the stage for what's coming after. Or, if you are impatient, [jump straight to the ODE model implementation](/posts/2024-02-17-longitudinal-multilevel-bayes-7/).\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}