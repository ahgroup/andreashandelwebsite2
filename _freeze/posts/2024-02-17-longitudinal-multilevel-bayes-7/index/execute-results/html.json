{
  "hash": "fe3c9c0bc660bb8668b17f1a6ae474da",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Bayesian analysis of longitudinal multilevel data using brms and rethinking - part 7  \ndescription: In part 7 of this series, I show how to fit a very simple ODE model using Stan.\nauthor: Andreas Handel\ndate: 2024-02-17\ndate-modified: last-modified\naliases: \n  - ../longitudinal-multilevel-bayesian-analysis-7/\ncategories: \n- R\n- Data Analysis\n- Bayesian\n- Stan\nimage: \"featured.png\"\nimage-alt: \"trajectories generated by ODE model\"\nexecute:\n  echo: true\nengine: knitr\n---\n\n\n\n\n# Overview\n\nThis tutorial continues [the series of posts](/posts/2022-02-22-longitudinal-multilevel-bayes-1/)\nshowing how to fit longitudinal data using Bayesian multilevel/hierarchical/mixed-effects models. To be able to follow along, you should start with the first post. Otherwise, the following won't make much sense üòÅ.\n\nThis tutorial starts the example where the underlying model is given by a set of ordinary differential equations (ODEs). This was originally meant to be a single post, but -- perhaps not surprisingly -- I couldn't get the model I wanted to work. To debug, I had to go slower and had to resort to first fiddling with a simpler model.\n\nI figured these intermediate steps might be useful for folks, so instead of hiding it and just showing you the final model -- which I eventually managed to get working, -- I decided to also write up these intermediate steps. \n\nSo this post introduces the ODE model and a simple statistical model, and then in the [next post](/longitudinal-multilevel-bayes-8/), I finally do the model I wanted to do.\n\nHere is [the Stan code for this example](stancode-ode-simple.stan) and this is [the R script that runs everything](cmdstanr-ode-simple-script.R).\n\n\n\n# Introduction\n\nA while ago, I wrote [a series of tutorials](/posts/2022-02-22-longitudinal-multilevel-bayes-1/) that discuss fitting longitudinal data using Bayesian multilevel/hierarchical/mixed-effects models.\n\nFor the first few posts in this series, I used the [`rethinking`](/posts/2022-02-22-longitudinal-multilevel-bayes-2/) and [`brms`](/posts/2022-02-22-longitudinal-multilevel-bayes-3/) packages to run `Stan` models in `R`, without having to write `Stan` code. \n\nIn those examples, I had a simple model that captured the longitudinal data (in my example, virus load) trajectory. For a research project, I now want to implement a model that uses a set of ordinary differential equations (ODEs). I figured to understand what I'm trying to do, I should first teach myself and write it up in a tutorial. \n\nOne can use packages like `rethinking` or `brms` with ODE models, but one still has to write some `Stan` code. I decided instead, for my purpose, it is better to write the full model in `Stan` and then fit it through `cmdstanr` in R.\n\nI had to go slow, so I can follow along üòÅ. I first switched to `cmdstanr` and `Stan` code using [one of the original models](/posts/2024-02-15-longitudinal-multilevel-bayes-5/) and then a [more complex model](/posts/2024-02-16-longitudinal-multilevel-bayes-6/) implemented in Stan. I assume you read those posts. In this post, I'll finally move on to an ODE-based model.\n\n\n\n\n# The idea\n\nThe most common types of models used to describe data are those that are non-mechanistic, or phenomenological, as [I like to call them](https://www.nature.com/articles/s41577-019-0235-3). What's meant by that is that the model represents a convenient and suitable way to describe the data, but does not try to capture any information about the underlying mechanisms of the system and processes that led to the observed data.\n\nIn contrast, mechanistic models are -- very simplified -- representations of the assumed or known underlying processes. As such, they allow incorporation of expert knowledge, and are potentially better at providing a fuller understanding of the system. Though they also require such a better understanding at the start to even allow using such models. \n\nThat's all I'll say about these models, you can learn more in [this review article I wrote with colleagues](https://www.nature.com/articles/s41577-019-0235-3) or on [this website](https://andreashandel.github.io/SMIcourse/). Both of these resources are immunology-focused, but the general concepts are the same for any subject matter area.\n\nA common way of implementing mechanistic models that describe the dynamics of some system is through ordinary differential equations (ODEs). This is the approach I'll be taking here.\n\n\n# The ODE model\n\nAs a reminder, our outcome/data of interest are virus load time-series trajectories of individuals following infection.\n\nTo get an ODE model that can capture the shape of our data, I use a simple basic virus dynamics model. I won't explain this model here, if you want to learn more about these kind of models, see for instance [this short write-up](https://andreashandel.github.io/SMIcourse/A_Few_Simple_Models.html#Simple_Viral_Infection_Model) on my [Simulation Modeling for Immunologists website](https://andreashandel.github.io/SMIcourse/) or [this reference](https://www.nature.com/articles/nri700).\n\nHere are the model equations\n\n$$\n\\begin{aligned}\n\\textrm{uninfected cells:} \\qquad  \\dot U & = -\\beta_i UV \\\\ \n\\textrm{infected cells:} \\qquad  \\dot I & = \\beta_i UV - \\gamma_i I \\\\\n\\textrm{virus:} \\qquad  \\dot V & = \\alpha_i I - \\eta_i V\n\\end{aligned}\n$$\nThis model has 4 parameters, each is indexed by $i$ to indicate that it can differ between individuals. For any ODE model, one needs to not only specify the model parameters but also the starting values of each quantity. To keep things simple, below I assume that the number of uninfected cells and infected cells is known and the same for each individual, and that the virus load is estimated but only depends on dose, no individual-level variation. More generally, it would be possible to let the starting values vary and estimate them from the data.\n\nWhile the model tracks the dynamics of 3 quantities, we only have data for one, namely the virus $V$. The log of the time-series obtained for $V$ by solving these ODEs is what is now assumed to be the average trajectory, namely what we formerly called $\\mu$ in the previous models.\n\n\n\n# Mathematical shenanigans\n\nAs is common, it turns out that directly coding up the model in the form specified above is not a good idea for several reasons.\n\nFirst, we have the issue with positive parameters again. The model above assumes all parameters are positive. To enforce that, we can again use the trick of exponentiating the parameters. This is what we'll do. You'll see it in the code below.\n\nSecond the values for the model variables change a lot. We start with a lot of uninfected cells (millions or more), no infected cells and a little bit of virus. The virus then grows rapidly, and so do the infected cells. The uninfected cell numbers crash. These extreme changes in variables are hard on the ODE solver. I initially tried to implement the model as written above (after enforcing parameters to be positive by exponentiating), and then in the end take the log of the virus load. That didn't work well. So I decided to just run the whole model in log units. \n\nThat means, the model I'm actually running is\n\n\n$$\n\\begin{aligned}\n\\textrm{uninfected cells:} \\qquad  \\frac{d}{dt} \\log(U) & = -\\exp(\\beta_i) \\log(U) \\log(V) \\\\ \n\\textrm{infected cells:} \\qquad  \\frac{d}{dt} \\log(I) & = \\exp(\\beta_i) \\log(U) \\log(V) - \\exp(\\gamma_i) \\log(I) \\\\\n\\textrm{virus:} \\qquad  \\frac{d}{dt} \\log(V) & = \\exp(\\alpha_i) \\log(I) - \\exp(\\eta_i) \\log(V)\n\\end{aligned}\n$$\n\n\nI want to re-iterate that this is the same model as above, just doing various transformations to make the code run.\n\n\n# ODE model exploration\n\nTo get a quick idea for the model behavior, I wrote a few lines of R code to run it.\n\nFirst, we load all packages needed for this whole post/project, and set some variables/paths.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary('here') #for file loading\nlibrary('dplyr') # for data manipulation\nlibrary('ggplot2') # for plotting\nlibrary('fs') #for file path\nlibrary('cmdstanr') #for model fitting\nlibrary('bayesplot') #for plotting results\nlibrary('loo') #for model diagnostics\nlibrary(\"deSolve\") #to explore the ODE model in R\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n############################################\n# some general definitons and setup stuff\n############################################\n#setting random number seed for reproducibility\nrngseed = 1234\n# File locations and names\n# adjust as needed\nfilepath = fs::path(\"D:\",\"Dropbox\",\"datafiles\",\"longitudinalbayes\")\nfilename = \"cmdstanr-ode-simple.Rds\"\nstanfile <- here('posts','2024-02-17-longitudinal-multilevel-bayes-7',\"stancode-ode-simple.stan\")\nsimdatloc <- here::here('posts','2022-02-22-longitudinal-multilevel-bayes-1','simdat.Rds')\n```\n:::\n\n\n\nNext, a few lines of code to explore the ODE model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# brief plotting of model to get idea for priors\nodemod <- function(t,y,parms) \n  {\n    alph = parms[1]; bet = parms[2]; gamm = parms[3]; et = parms[4]\n    dU = - bet*y[1]*y[3]\n    dI = bet*y[1]*y[3] - gamm*y[2]\n    dV = alph*y[2] - et*y[3]\n    return(list(c(dU,dI,dV)))\n}\n# initial conditions, on log scale \n# Uninfected cells, infected cells, virus\n# note that I'm starting with 1 infected cells so I can take the log\n# also, the starting value for V has the extra exponent because I'll be\n# fitting this as a free parameter and therefore also need to do to \n# exponentiation trick\ny0 = log(c(1e8,1,exp(5)))\nt = seq(0,10,length=100)\n# some parameter values that lead to a decent curve\nalph = 3\nbet = -1\ngamm = 1 \net = 1\n# all parameters\nparms = exp(c(alph=alph,bet=bet,gamm=gamm,et=et))\n# reproductive number, gives an indication of virus growth\n# needs to be >1 \nR0 = exp(bet)*exp(alph)*y0[3]/(exp(gamm)*exp(et))\nprint(R0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5\n```\n\n\n:::\n\n```{.r .cell-code}\n# run the ODE model\noderes <- ode(y = y0, t = t, func = odemod, parms = parms)\n# look at virus load trajectory\n# note that it's already on the log scale\nplot(oderes[,1],oderes[,4])\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/explore-model-1.png){width=672}\n:::\n:::\n\n\nI played around with the parameter values to find some that gives me a curve that looks reasonable.\n\n\n\n## The new statistical model\n\nI wanted a statistical model that had the overall structure of the model structure from the previous non-ODE model examples, with the only difference that now the virus trajectory is described by an ODE model. I'll get to this in the next blog post. But I wasn't able to get that model to work and therefore had to resort to building a simpler model first, just to figure out what's going on.\n\nFor the simpler model, I used the approach from the last model in the previous post, namely a model for which the main parameters are different for each individual and don't depend on dose or each other. The initial value for the virus variable is assumed to depend on dose. \n\nI'm not sure what the best mathematical notation is to write down this model, here is an option. I'm showing the ODE model in its original form, without the extra $\\exp()$ and $\\log()$ notation. The understanding is that model will be implemented as shown in the second model above, with parameters on an exponentiated scale and variables on the log scale. This is reflected in the initial condition values.\n\n\n$$\n\\begin{aligned}\n\\textrm{Outcome} \\\\\nY_{i,t}   \\sim \\mathrm{Normal}\\left(V_{i,t}, \\sigma\\right) \\\\\n\\\\\n\\textrm{ODE model defining V} \\\\\n\\dot U  = -\\beta_i UV \\\\ \n\\dot I  = \\beta_i UV - \\gamma_i I \\\\\n\\dot V  = \\alpha_i I - \\eta_i V \\\\\n\\\\\n\\textrm{Starting values for ODE model} \\\\\n\\textrm{initial uninfected cells} \\qquad U(0) = \\log(1E8)  \\\\\n\\textrm{initial infected cells} \\qquad  I(0) = 0  \\\\\n\\textrm{initial virus, to be fit}  \\qquad V(0) = V_i[dose] \\\\\n\\\\\n\\textrm{Deterministic models for main parameters} \\\\\n\\alpha_{i}   =  a_{0,i}  \\\\\n\\beta_{i}   =   b_{0,i} \\\\\n\\gamma_{i}   =   g_{0,i} \\\\\n\\eta_{i}   =   e_{0,i} \\\\\n\\end{aligned}\n$$\nThe index $i$ represents indexation with respect to individuals. The index $dose$ indicates the 3 different dose levels. \n\nAs mentioned before, I don't really need both $\\alpha, \\beta,...$ here and $a_0, b_0,...$, but I'm setting this up this way so it's similar to all previous setups and easy to extend.\n\nTo fully specify the model, we need to give all parameters distributions. As before, I'm not showing the exact prior values to prevent it being different than the code, instead I'm only indicating them here with an `X`. See the code for the exact values. \n\nAs mentioned, I'm not yet implementing partial pooling, instead each parameter has some fixed prior distribution. As a reminder, the parameters inside the ODE are the exponentiated version of this, while the starting value for the virus load is on a log scale (so the true value is the exponentiated form, but we never use that, we fully operate on a log scale for all 3 ODE model variables).\n\n\n$$\n\\begin{aligned}\n\\textrm{population-level priors} \\\\\n\\sigma  \\sim \\mathrm{HalfCauchy}(X,X)  \\\\\na_{0,i} \\sim \\mathrm{Normal}(X, X) \\\\\nb_{0,i} \\sim \\mathrm{Normal}(X, X) \\\\\ng_{0,i} \\sim \\mathrm{Normal}(X, X) \\\\\ne_{0,i} \\sim \\mathrm{Normal}(X, X) \\\\\nV_i[dose] \\sim \\mathrm{Normal}(X, X) \\\\\n\\end{aligned}\n$$\n\n\nAnd that's the full model for the simplified case. Now we need to implement it with Stan. \n\n\n\n# Model implementation\n\nWe previously used the `brms` and `rethinking` R packages to run our `Stan` models in `R`, without having to write `Stan` code. One can use these packages for ODEs, but still has to write some `Stan` code. I decided instead, for flexibility, I'm writing the full model in `Stan` and then fit it through `cmdstanr` in R.\n\nWe'll use the same data as before. We need to reshape it a bit to get it into the format that `cmdstanr` requires. To make things inside the Stan code easier, we added some additional information. Note that the model we implement here won't use all of the data. We keep it in here for the next model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading data, path set in setup\nsimdat <- readRDS(simdatloc)\n# using dataset 3 for fitting\n# formatted for Stan use\nNtot =  length(simdat$m3$id) #total observations\nNind = length(unique(simdat$m3$id)) #number of individuals\nNobs = as.numeric(table(simdat[[3]]$id)) #number of observations per individual, the same for everyone here\nNdose = length(unique(simdat$m3$dose_adj))\n# values for prior distributions\n# allows for exploring different values without having to edit Stan model code\npriorvals = list(a0_mu = 3, a0_sd = 1,\n                 b0_mu = -1, b0_sd = 1,\n                 g0_mu = 1, g0_sd = 1,\n                 e0_mu = 1, e0_sd = 1,\n                 V0_mu = exp(5), V0_sd = 10\n)\n\n# all data as one list, this is how Stan needs it\nfitdat=list(id=simdat[[3]]$id, #an ID for each individual, for indexing\n            outcome = simdat[[3]]$outcome, #all outcomes\n            time = simdat[[3]]$time, #all times\n            dose_adj = simdat[[3]]$dose_adj[1:Nind],\n            dose_level = as.numeric(factor(simdat[[3]]$dose_adj[1:Nind])), #dose category for each individual\n            Ntot =  Ntot,\n            Nobs =  Nobs,\n            Nind = Nind,\n            Ndose = Ndose,\n            tstart = 0\n            )\nfitdat = c(fitdat,priorvals)\n```\n:::\n\n\n\n# Stan code\n\nNext, we need to write the Stan model code. For some of the parts, I took inspiration from [this blog post by Danielle Narravo](https://blog.djnavarro.net/posts/2023-06-10_pop-pk-models/). The code is again in a separate file, linked at the top of this post. \n\nThe code keeps growing. I'm not going to explain it in detail, but will point out a few new parts. \n\n* There is now a `functions` block which defines the ODE model function. The notation is rather similar to the `deSolve` R implementation shown above. This function is called inside the `generated parameters` block and integrated using the `ode_rk45` routine that is part of Stan. \n\n* For the `data` part, I'm passing in values for priors for all parameters. I also now have a variable `dose_level` that is an indicator variable taking on values 1,2,3 for the 3 different dose levels, and used to index the starting value for the virus load, which we assume only differs by dose and not individual person.\n\n* There's also a `transformed data` block that computes some indices to keep track of the first and last value of each individual in the long vector of all observations. \n\n* The ode integration happens inside the `generated parameters` block. We loop over every individual and run the ODE model, then save the results for each individual in the long `virus_pred` vector.\n\n\n```{.stan include=\"stancode-ode-simple.stan\"}\n```\n\n\nNext, we load and compile the Stan model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make Stan model. \nstanmod1 <- cmdstanr::cmdstan_model(stan_file = stanfile, \n                                    compile = TRUE,\n                                    pedantic=TRUE,\n                                    force_recompile=TRUE)\n```\n:::\n\n\n\n# Model fitting settings\n\nAs before, we need to specify settings for the MCMC algorithm and starting values (the latter of which is optional but I consider good practice).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#settings for fitting\nfs_m1 = list(warmup = 1500,\n             sampling = 1000, \n             max_td = 15, #tree depth\n             adapt_delta = 0.99,\n             chains = 2,\n             cores  = 2,\n             seed = 1234,\n             save_warmup = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# separate definition of initial values, added to fs_m1 structure \n# a different sample will be drawn for each chain\n# there's probably a better way to do that than a for loop\nset.seed(rngseed) #make inits reproducible\ninit_vals_1chain <- function() (list(a0 = runif(Nind,3,4),\n                                     b0 = runif(Nind,-1,-1),\n                                     g0 = runif(Nind,1,1),\n                                     e0 = runif(Nind,1,1),\n                                     sigma = runif(1,0,1),\n                                     V0 = runif(Ndose,4,6)\n                                     ))\n\ninits = NULL\nfor (n in 1:fs_m1$chains)\n{\n  inits[[n]] = init_vals_1chain()\n}\nfs_m1$init = inits\n```\n:::\n\n\n\n# Model fitting \n\n\nThis runs the model. It's not actually run here to speed up generation of this Quarto file, but the code chunk is in the R script, so you can run it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_m1 <- stanmod1$sample(data = fitdat,\n                          chains = fs_m1$chains,\n                          init = fs_m1$init,\n                          seed = fs_m1$seed,\n                          parallel_chains = fs_m1$chains,\n                          iter_warmup = fs_m1$warmup,\n                          iter_sampling = fs_m1$sampling,\n                          save_warmup = fs_m1$save_warmup,\n                          max_treedepth = fs_m1$max_td,\n                          adapt_delta = fs_m1$adapt_delta,\n                          output_dir = filepath\n                          \n)\n```\n:::\n\n\nIf you were to run it, you'll find that it takes rather long. That's a major problem with ODE model fitting in a Bayesian framework. Those models take long to run and one needs to run them for each iteration. In the future, I hope to re-implement this in `Julia`, which is a programming language that has faster ODE solvers. But I don't have a ton of Julia experience, so this will come after I fully get this example to work üòÅ.\n\n\n# Model result loading\n\nTo save time, we don't run the model each time, instead we save the results and load them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading previously saved fit.\n# useful if we don't want to re-fit\n# every time we want to explore the results.\n# since the file is too large for GitHub\n# it is stored in a local cloud-synced folder\n# adjust accordingly for your setup\nres_m1 <- readRDS(fs::path(filepath,filename))\n```\n:::\n\n\n\n# Model exploration\n\nGet the samples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#this uses the posterior package to get draws\nsamp_m1 <- res_m1$draws(inc_warmup = FALSE, format = \"draws_df\")\nallsamp_m1 <- res_m1$draws(inc_warmup = TRUE, format = \"draws_df\")\n```\n:::\n\n\n\nModel diagnostics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_m1$cmdstan_diagnose()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nProcessing csv files: D:/Dropbox/datafiles/longitudinalbayes/stancode-ode-simple-202402271859-1-8dba1c.csvWarning: non-fatal error reading adaptation data\n, D:/Dropbox/datafiles/longitudinalbayes/stancode-ode-simple-202402271859-2-8dba1c.csvWarning: non-fatal error reading adaptation data\n\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n```\n\n\n:::\n:::\n\n\nOk, so the sampler isn't quite happy. \n\nNext, we'll take a look at a summary table for the distributions of some of the model parameters. I cut it off since there are too many to show (each individual as multiple parameters with associated distributions).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# uses posterior package \nprint(head(res_m1$summary(),15))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 √ó 10\n   variable    mean  median    sd   mad       q5     q95  rhat ess_bulk ess_tail\n   <chr>      <dbl>   <dbl> <dbl> <dbl>    <dbl>   <dbl> <dbl>    <dbl>    <dbl>\n 1 lp__     -1.09e3 -1.09e3 7.52  7.41  -1.11e+3 -1.08e3  1.00     535.     957.\n 2 sigma     2.93e1  2.93e1 1.38  1.38   2.71e+1  3.15e1  1.00    1183.    1349.\n 3 a0[1]     2.31e0  2.30e0 0.861 0.832  8.90e-1  3.72e0  1.00    3456.    1567.\n 4 a0[2]     2.28e0  2.29e0 0.870 0.855  8.84e-1  3.73e0  1.00    2920.    1592.\n 5 a0[3]     2.49e0  2.50e0 0.865 0.863  1.06e+0  3.89e0  1.00    3106.    1516.\n 6 a0[4]     2.65e0  2.61e0 0.968 0.932  1.03e+0  4.30e0  1.00    2953.    1540.\n 7 a0[5]     2.67e0  2.66e0 0.951 0.955  1.12e+0  4.25e0  1.00    2952.    1566.\n 8 a0[6]     2.93e0  2.92e0 0.941 0.934  1.40e+0  4.51e0  1.00    3241.    1506.\n 9 a0[7]     2.93e0  2.94e0 0.973 1.00   1.30e+0  4.53e0  1.00    2831.    1501.\n10 a0[8]     3.02e0  3.02e0 0.989 0.975  1.39e+0  4.69e0  1.01    2729.    1389.\n11 a0[9]     3.13e0  3.17e0 0.969 0.964  1.51e+0  4.65e0  1.00    2953.    1434.\n12 a0[10]    3.01e0  3.02e0 1.04  1.05   1.26e+0  4.66e0  1.00    4447.    1438.\n13 a0[11]    3.22e0  3.22e0 0.972 0.994  1.61e+0  4.78e0  1.00    2040.    1246.\n14 a0[12]    3.00e0  2.98e0 0.985 0.995  1.39e+0  4.64e0  1.00    3587.    1600.\n15 a0[13]    3.29e0  3.27e0 0.981 0.960  1.68e+0  4.89e0  1.00    2005.    1542.\n```\n\n\n:::\n:::\n\n\nWe can't really compare with the values we used to generate the model since we are using a different model to fit the data. However, since we have a mechanistic model, and the parameters have biological meaning, we can do a reality-check, at least for some of them. For instance the inverse of the parameter $\\gamma$ is the lifespan of an infected cell. If we have some knowledge of the system, we can see if our estimate agrees with that. Even without much knowledge, we would still expect an infected cell at minimum to live on average say a few hours -- otherwise it could never produce any virus -- and at most maybe days/weeks/months, depending on the pathogen we model. So if our predictions correspond to lifespans of seconds or millenia, we know something isn't right. The fact that model parameters have biological meaning is unique to mechanistic models. For phenomenological models (e.g., some type of GLM), interpretation of parameters is not as clear. Though even in those situations, one can often spot parameters that make no sense. For instance a prediction that each 1 pound increase in weight for children leads to increase in 1 meter of height is clearly nonsensical. So it's always important to look at the parameter values and contemplate if they make sense, given what we know about the real world.\n\n\nLet's again look at a few plots to make sure everything looks reasonable. Here I'm showing again a trace plot and a posterior density plot. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# only a few parameters\nplotpars = c(\"a0[1]\",\"b0[1]\",\"g0[1]\",\"e0[1]\",\"sigma\")\nbayesplot::color_scheme_set(\"viridis\")\nbp1 <- bayesplot::mcmc_trace(samp_m1, pars = plotpars)\nbp3 <- bayesplot::mcmc_dens_overlay(samp_m1, pars = plotpars)\nplot(bp1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_par_m1-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(bp3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_par_m1-2.png){width=672}\n:::\n:::\n\n\nThe pairs plot shows a strong correlation between $\\beta$ and $\\gamma$.\n\n\nNext, we'll compare prior and posterior distributions. This can give an indication if the priors were selected well or are too broad or overly influential. To be able to show priors, we needed all that extra information in the _generated quantities_ block in the Stan code.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# data manipulation to get in shape for plotting\n# data manipulation to get in shape for plotting\n# start with manipulation of posterior parameters\npostdf1 <- samp_m1 %>% \n  select(!ends_with('prior')) %>% \n  select(contains(\"sigma\")) \n# akward way of getting some further parameters\n# namely values from first individual for a0,b0,g0,e0\npostdf2 <- samp_m1 %>%\n  select(contains(\"0[1]\")) %>%\n  rename_with(~ gsub(\"[1]\", \"\", .x, fixed = TRUE) )\npostdf <- cbind(postdf1, postdf2) \npostlong <- tidyr::pivot_longer(data = postdf, \n                                cols = everything() , \n                                names_to = \"parname\", \n                                values_to = \"value\") %>% \n  dplyr::mutate(type = \"posterior\")\n# manipulation of prior parameters\npriordf <-  samp_m1 %>% \n  select(ends_with('prior')) %>% \n  rename_with(~ gsub(\"_prior\", \"\", .x, fixed = TRUE) ) \npriorlong <- tidyr::pivot_longer(data = priordf, \n                                 cols = everything() , \n                                 names_to = \"parname\", \n                                 values_to = \"value\") %>% \n  dplyr::mutate(type = \"prior\")\n\nppdf <- dplyr::bind_rows(postlong,priorlong)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_p1 <- ppdf %>%\n  ggplot() +\n  geom_density(aes(x = value, color = type), linewidth = 1) +\n  facet_wrap(\"parname\", scales = \"free\") +\n  theme_minimal()\nplot(m1_p1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/prior_post_m1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# just to get a picture that can be shown together with the post\n#ggsave(\"featured.png\",m1_p1)\n```\n:::\n\n\nThe plots show that the priors don't overly influence the results, the data dominates the posteriors (they move and get more peaked, an indication that the data controls the posterior shape).\n\n\nI'm skipping the additional diagnostics with the `loo` package, the same code as in the previous examples would work. I'm also not showing the observed versus predicted plot, since we will look at the actual data and model predictions, which for this type of model is more informative.\n\n\n# Model predictions\n\nFinally, we again want to look at the actual data and the model predictions. It's exactly the same code as for the 2-parameter model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# averages and CI for \n# estimates of deterministic model trajectory\n# for each observation\n# this is computed in the transformed parameters block of the Stan code\nmu <- samp_m1 |>\n  select(starts_with(\"virus_pred\")) |>\n  apply(2, quantile, c(0.05, 0.5, 0.95)) |>\n  t() \nrownames(mu) <- NULL\n\n# estimate and CI for prediction intervals\n# the predictions factor in additional uncertainty around the mean (mu)\n# as indicated by sigma\n# this is computed in the predicted-quantities block of the Stan code\n# the average of mu and preds should be more or less the same\n# but preds will have wider uncertainty due to the residual variation sigma\npreds <- samp_m1 |>\n  select(starts_with(\"ypred\")) |>\n  apply(2, quantile, c(0.05, 0.5, 0.95)) |>\n  t() \nrownames(preds) <- NULL\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# change dose so it looks nicer in plot\ndose = as.factor(fitdat$dose_adj)\nlevels(dose)[1] <- \"low\"\nlevels(dose)[2] <- \"medium\"\nlevels(dose)[3] <- \"high\"\n\n#place everything into a data frame\nfitpred = data.frame(id = as.factor(fitdat$id),\n                     dose = dose,\n                     time = fitdat$time,\n                     Outcome = fitdat$outcome,\n                     Estimate = mu[,2],\n                     Qmulo = mu[,1], Qmuhi = mu[,3]\n                     #Qsimlo = preds[,1], Qsimhi = preds[,3]\n)\n\n#make the plot\npredplot <- ggplot(data = fitpred, aes(x = time, y = Estimate, group = id, color = dose ) ) +\n  geom_line() +\n  #geom_ribbon(aes(x=time, ymin=Qmulo, ymax=Qmuhi, fill = dose, color = NULL), alpha=0.3, show.legend = F) +\n  #geom_ribbon(aes(x=time, ymin=Qsimlo, ymax=Qsimhi, fill = dose, color = NULL), alpha=0.1, show.legend = F) +\n  geom_point(aes(x = time, y = Outcome, group = id, color = dose), shape = 1, size = 2, stroke = 2) +\n  scale_y_continuous(limits = c(-30,50)) +\n  labs(y = \"Virus load\",\n       x = \"days post infection\") +\n  theme_minimal() \nplot(predplot)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_predictions-1.png){width=672}\n:::\n:::\n\n\nThe model fits don't look that great. I'm not sure why the model isn't capturing the data better, if it needs more iterations and/or better choice of priors, or if there's something inherent about the structure of this model not being able to capture the data generated by the 2-parameter model, even though it is more flexible with its 4 parameters.\n\n\n\n# Summary and continuation\n\nThis completes the first half of the ODE model example. I'm finally ready to implement the more detailed model I really want to look at, which [is covered in the next post](/posts/2024-02-18-longitudinal-multilevel-bayes-8/).\n\n\n\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}